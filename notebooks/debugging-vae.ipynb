{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb25c6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 07:59:26.846914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744977566.858321    8329 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744977566.861763    8329 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-18 07:59:26.875284: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Could not load bitsandbytes native library: 'NoneType' object has no attribute 'split'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shaunak/.virtualenvs/ML/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/home/shaunak/.virtualenvs/ML/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 64, in get_native_library\n",
      "    cuda_specs = get_cuda_specs()\n",
      "  File \"/home/shaunak/.virtualenvs/ML/lib/python3.10/site-packages/bitsandbytes/cuda_specs.py\", line 39, in get_cuda_specs\n",
      "    cuda_version_string=(get_cuda_version_string()),\n",
      "  File \"/home/shaunak/.virtualenvs/ML/lib/python3.10/site-packages/bitsandbytes/cuda_specs.py\", line 29, in get_cuda_version_string\n",
      "    major, minor = get_cuda_version_tuple()\n",
      "  File \"/home/shaunak/.virtualenvs/ML/lib/python3.10/site-packages/bitsandbytes/cuda_specs.py\", line 24, in get_cuda_version_tuple\n",
      "    major, minor = map(int, torch.version.cuda.split(\".\"))\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "\n",
      "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "and open an issue at: https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4eec6a61f74724b9986e8bc13f845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "# Load the pipeline (no need for scheduler, text encoder, etc.)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch_dtype\n",
    ")\n",
    "pipe = pipe.to(device)\n",
    "_ = pipe.vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa55e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of latents (should not be None): tensor([[[[ 24.0160,  17.1888,  16.1042,  ...,  18.8757,  18.0343,  19.4322],\n",
      "          [ 23.0236,  18.8044,  15.4070,  ...,  17.8581,  13.1207,  21.1108],\n",
      "          [ 16.7784,  18.2736,  19.2088,  ...,  51.8460, -14.1167,  17.5220],\n",
      "          ...,\n",
      "          [ 22.9365,   8.2854,  18.9523,  ...,  19.0432,  19.7006,  19.5057],\n",
      "          [ 20.4679,  21.6788,  11.6978,  ...,  18.4686,  13.2063,   9.5370],\n",
      "          [ 15.4416,  24.6368,  18.8424,  ...,  13.3929,  21.0996,  14.3285]],\n",
      "\n",
      "         [[ 10.8740,  11.5339,  13.3749,  ...,   8.1413,  15.2031,  11.4969],\n",
      "          [ 11.6101,  13.9532,  12.2978,  ...,   9.2128,   8.2065,  13.7141],\n",
      "          [ 14.3990,  16.4335,  13.8345,  ...,   9.2702,  24.3216,  13.3538],\n",
      "          ...,\n",
      "          [ 15.3893,  15.3023,  16.0283,  ...,  14.5434,  14.8369,  14.0364],\n",
      "          [ 11.4864,  21.0988,   9.4449,  ...,  14.3880,  10.0669,  10.4385],\n",
      "          [ 19.8336,  16.6974,  15.6520,  ...,  14.9978,   7.4506,  12.3886]],\n",
      "\n",
      "         [[  3.4781,   2.8042,   4.0688,  ...,   5.4212,  11.9840,   3.5528],\n",
      "          [ -1.6183,  -0.1665,   3.8878,  ...,  -0.3354,  -4.1658,  10.6134],\n",
      "          [ -3.0973,   1.7705,   7.2468,  ..., -64.4774,  16.0693,   9.5843],\n",
      "          ...,\n",
      "          [  1.7665,   0.4295,  14.1587,  ...,   6.9722,   8.1681,   9.0179],\n",
      "          [  3.0919,  -3.1413,   3.3458,  ...,   4.9504,   0.2894,   6.6204],\n",
      "          [  5.8187,  11.4236,  -4.5917,  ...,   6.1393,   7.9994,   2.3219]],\n",
      "\n",
      "         [[-23.9602, -20.6113, -21.4408,  ..., -28.8091, -28.8706, -17.7234],\n",
      "          [-16.9420, -23.2662, -23.7992,  ..., -26.8423, -23.3246, -27.9601],\n",
      "          [-21.9712, -18.1471, -20.9552,  ..., -34.8896,  -5.3448, -19.2251],\n",
      "          ...,\n",
      "          [-24.2576, -21.1773, -24.1490,  ..., -18.5256, -19.9025, -21.6598],\n",
      "          [-29.3386, -15.7542, -22.8839,  ..., -34.7815, -23.3404, -17.7904],\n",
      "          [-13.5157, -33.3767, -25.0587,  ..., -17.1109, -23.4456, -16.9928]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "latents = torch.randn(1, 4, 64, 64, device=device, dtype = torch_dtype, requires_grad=True)\n",
    "\n",
    "with torch.enable_grad():\n",
    "    decoded = pipe.vae.decode(latents)  # Returns SampleOutput\n",
    "    image = decoded.sample  # This may be detached\n",
    "\n",
    "# Check if gradients flow\n",
    "scalar = image.sum()\n",
    "scalar.backward()\n",
    "\n",
    "print(\"Gradient of latents (should not be None):\", latents.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851b6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
